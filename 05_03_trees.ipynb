{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPD+Oub9mkavwIuB4BJNnks"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"jzbril0g4vS6","executionInfo":{"status":"ok","timestamp":1691577669357,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jinho Lee","userId":"08146136824216286627"}}},"outputs":[],"source":["# Ensemble Learning\n","\n","# bootstrap sample\n","# 데이터 세트에서 중복을 허용하여 데이터를 샘플링하는 방식\n","\n","\n","# 랜덤 포레스트는 결정 트리를 랜덤하게 만들어 결정 트리(나무)의 숲을 만듭니다.\n","# 그리고 각 결정 트리의 예측을 사용해 최종 예측을 만듭니다\n","#\n","#\n","# bootstrap 방식으로 sample 추출\n","# 분류 모델인 RandomForestClassifier는 기본적으로 전체 특성 개수의 제곱근만큼의 특성을 무작위로 선택\n","# 다음 이 중에서 최선의 분할을 찾습니다\n","\n","# 사이킷런에서는 100개 트\n"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","wine = pd.read_csv('https://bit.ly/wine_csv_data')\n","data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n","target = wine['class'].to_numpy()\n","train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)\n","\n","from sklearn.model_selection import cross_validate\n","from sklearn.ensemble import RandomForestClassifier\n","rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n","\n","# 평가할 모델 객체를 첫 번째 매개변수로 전달\n","# 그다음 앞에서처럼 직접 검증 세트를 떼어 내지 않고 훈련 세트 전체를 cross_validate() 함수에 전달\n","scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n","\n","# 하나의 특성에 과도하게 집중하지 않고 좀 더 많은 특성이 훈련에 기여할 기회를 얻습니다.\n","# 이는 과대적합을 줄이고 일반화 성능을 높이는 데 도움이 됩니다"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"86XEQuhg4qX0","executionInfo":{"status":"ok","timestamp":1691578462815,"user_tz":-540,"elapsed":4584,"user":{"displayName":"Jinho Lee","userId":"08146136824216286627"}},"outputId":"4dab8673-5bab-4ff6-ee8c-65604796631a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9973541965122431 0.8905151032797809\n"]}]},{"cell_type":"code","source":["rf.fit(train_input, train_target)\n","print(rf.feature_importances_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xCp9vObM6YFO","executionInfo":{"status":"ok","timestamp":1691578470481,"user_tz":-540,"elapsed":1136,"user":{"displayName":"Jinho Lee","userId":"08146136824216286627"}},"outputId":"6525a856-d0c7-414e-8feb-15c170118d86"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.23167441 0.50039841 0.26792718]\n"]}]},{"cell_type":"code","source":["# RandomForestClassifier에는 자체적으로 모델을 평가하는 점수를 얻을 수 잇음\n","# Out of Bag Sample (OOB): bootstrap 안된 샘플\n","# oob 샘플을 사용해서 검증\n","rf = RandomForestClassifier(oob_score = True, n_jobs = -1, random_state=42)\n","rf.fit(train_input, train_target)\n","print(rf.oob_score_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-_zE-keS7wjU","executionInfo":{"status":"ok","timestamp":1691578677953,"user_tz":-540,"elapsed":1144,"user":{"displayName":"Jinho Lee","userId":"08146136824216286627"}},"outputId":"5e89a055-ddd8-430e-ac71-154943a0909e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8934000384837406\n"]}]},{"cell_type":"code","source":["# Extra Trees\n","# 100개의 결정 트리 훈련\n","# 랜덤포레스트와는 다르게 부트스트랩 샘플을 사용하지 않음\n","# 대신 노드 분할 시 가장 좋은 분할이 아닌 무작위 분할\n","\n","\n","from sklearn.ensemble import ExtraTreesClassifier\n","et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n","scores = cross_validate(et, train_input, train_target,\n"," return_train_score=True, n_jobs=-1)\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n","\n","et.fit(train_input, train_target)\n","print(et.feature_importances_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kt3RrXDS8jNh","executionInfo":{"status":"ok","timestamp":1691578959993,"user_tz":-540,"elapsed":4710,"user":{"displayName":"Jinho Lee","userId":"08146136824216286627"}},"outputId":"127386dd-1c75-4f5f-ff48-11d665a12677"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9974503966084433 0.8887848893166506\n","[0.20183568 0.52242907 0.27573525]\n"]}]},{"cell_type":"code","source":["# Gradient Boosting\n","# 깊이가 얕은 결정 트리를 사용하여 이전 트리의 오차를 보완하는 방식으로 앙상블 하는 방법\n","# 사이킷런의 GradientBoostingClassifier는 기본적으로 깊이가 3인 결정 트리를 100개 사용\n","\n","\n","from sklearn.ensemble import GradientBoostingClassifier\n","gb = GradientBoostingClassifier(random_state = 42)\n","scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9GjGHMgg9nME","executionInfo":{"status":"ok","timestamp":1691580179930,"user_tz":-540,"elapsed":4046,"user":{"displayName":"Jinho Lee","userId":"08146136824216286627"}},"outputId":"960a9624-7fb4-4150-fe28-9eecff8dcf35"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8881086892152563 0.8720430147331015\n"]}]},{"cell_type":"code","source":["gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2,\n"," random_state=42)\n","scores = cross_validate(gb, train_input, train_target,\n"," return_train_score=True, n_jobs=-1)\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aqN_unxvCRMf","executionInfo":{"status":"ok","timestamp":1691580208815,"user_tz":-540,"elapsed":10212,"user":{"displayName":"Jinho Lee","userId":"08146136824216286627"}},"outputId":"f5e1aa54-39bd-461d-f1ef-303faa6ce59f"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9464595437171814 0.8780082549788999\n"]}]},{"cell_type":"code","source":["gb.fit(train_input, train_target)\n","print(gb.feature_importances_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bs-yiM_KCWvU","executionInfo":{"status":"ok","timestamp":1691580256534,"user_tz":-540,"elapsed":4459,"user":{"displayName":"Jinho Lee","userId":"08146136824216286627"}},"outputId":"ae9d7a65-c785-4866-c5fc-7c673f68d7ef"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.15872278 0.68010884 0.16116839]\n"]}]},{"cell_type":"code","source":["# histogram gradient boosting\n","from sklearn.experimental import enable_hist_gradient_boosting\n","from sklearn.ensemble import HistGradientBoostingClassifier\n","hgb = HistGradientBoostingClassifier(random_state=42)\n","scores = cross_validate(hgb, train_input, train_target,\n"," return_train_score=True)\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n","\n","from sklearn.inspection import permutation_importance\n","hgb.fit(train_input, train_target)\n","# 특성 중요도를 계산\n","result = permutation_importance(hgb, train_input, train_target,\n"," n_repeats=10, random_state=42, n_jobs=-1)\n","print(result.importances_mean)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GfOWtikfCjzX","executionInfo":{"status":"ok","timestamp":1691580513559,"user_tz":-540,"elapsed":5309,"user":{"displayName":"Jinho Lee","userId":"08146136824216286627"}},"outputId":"3aa427df-564c-4383-db33-fbfe9b1650c1"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["0.9321723946453317 0.8801241948619236\n"]}]}]}